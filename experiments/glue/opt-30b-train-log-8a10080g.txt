Loading extension module utils...
Time to load utils op: 0.0003867149353027344 seconds
11/11/2022 03:22:05 
############# Model Arch of MT-DNN #############
SANBertNetwork(
  (dropout_list): ModuleList()
  (bert): OPTModel(
    (decoder): OPTDecoder(
      (embed_tokens): Embedding(50272, 7168, padding_idx=1)
      (embed_positions): OPTLearnedPositionalEmbedding(2050, 7168)
      (layers): ModuleList(
        (0): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (1): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (2): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (3): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (4): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (5): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (6): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (7): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (8): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (9): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (10): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (11): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (12): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (13): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (14): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (15): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (16): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (17): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (18): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (19): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (20): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (21): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (22): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (23): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (24): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (25): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (26): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (27): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (28): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (29): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (30): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (31): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (32): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (33): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (34): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (35): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (36): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (37): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (38): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (39): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (40): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (41): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (42): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (43): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (44): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (45): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (46): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
        (47): OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (v_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (q_proj): Linear(in_features=7168, out_features=7168, bias=True)
            (out_proj): Linear(in_features=7168, out_features=7168, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=7168, out_features=28672, bias=True)
          (fc2): Linear(in_features=28672, out_features=7168, bias=True)
          (final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (scoring_list): ModuleList(
    (0): Sequential(
      (0): Pooler(
        (dense): Linear(in_features=7168, out_features=7168, bias=True)
        (dropout): DropoutWrapper()
      )
      (1): Linear(in_features=7168, out_features=3, bias=True)
    )
  )
)

11/11/2022 03:22:05 Total number of params: 30025934851
11/11/2022 03:22:05 At epoch 0
11/11/2022 03:22:37 Task [ 0] updates[     1] train loss[0.76953] remaining[9 days, 5:06:17]
